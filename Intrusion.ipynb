{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tkinter import messagebox\n", "from tkinter import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tkinter import simpledialog\n", "import tkinter\n", "from tkinter import filedialog\n", "from tkinter.filedialog import askopenfilename\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.preprocessing import LabelEncoder\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.utils.np_utils import to_categorical\n", "from keras.layers import  MaxPooling2D\n", "from keras.layers import Dense, Dropout, Activation, Flatten\n", "from keras.layers import Convolution2D\n", "from keras.models import Sequential\n", "from keras.models import model_from_json\n", "import pickle\n", "import os\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import precision_score\n", "from sklearn.metrics import recall_score\n", "from sklearn.metrics import f1_score\n", "from sklearn.metrics import accuracy_score\n", "import webbrowser"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["main = tkinter.Tk()\n", "main.title(\"A Deep Learning Approach for Effective Intrusion Detection in Wireless Networks using CNN\")\n", "main.geometry(\"1000x900\")\n", "# Add image file\n", "img = PhotoImage(file=\"pic.png\")\n", "label = Label(\n", "    main,\n", "    image=img\n", ")\n", "label.place(x=5, y=350)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["global filename\n", "global X, Y\n", "labels = ['dos', 'probe', 'r2l', 'u2r']\n", "global dataset\n", "accuracy = []\n", "global output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def uploadDataset():\n", "    global filename\n", "    global dataset\n", "    filename = filedialog.askopenfilename(initialdir=\"Dataset\")\n", "    pathlabel.config(text=filename)\n", "    text.delete('1.0', END)\n", "    dataset = pd.read_csv(filename)\n", "    dataset.fillna(0, inplace = True)\n", "    text.insert(END,filename+\" loaded\\n\\n\");\n", "    text.insert(END,str(dataset.head()))\n", "    label = dataset.groupby('label').size()\n", "    plt.figure()\n", "    label.plot(kind=\"barh\",color=\"#473C8B\")\n", "    plt.show()\n", "                "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocessDataset():\n", "    global dataset\n", "    global X, Y\n", "    text.delete('1.0', END)\n", "    cols = ['protocol_type','service','flag','label']\n", "    le = LabelEncoder()\n", "    dataset[cols[0]] = pd.Series(le.fit_transform(dataset[cols[0]].astype(str)))\n", "    dataset[cols[1]] = pd.Series(le.fit_transform(dataset[cols[1]].astype(str)))\n", "    dataset[cols[2]] = pd.Series(le.fit_transform(dataset[cols[2]].astype(str)))\n", "    dataset[cols[3]] = pd.Series(le.fit_transform(dataset[cols[3]].astype(str)))\n", "    text.insert(END,\"Dataset preprocessing completed\\n\\n\")\n", "    text.insert(END,str(dataset.head()))\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def CNNFullFeatures():\n", "    global output\n", "    global accuracy\n", "    global dataset\n", "    global X, Y\n", "    Y = dataset['label'].tolist()\n", "    Y = np.asarray(Y)\n", "    dataset.drop(['label'], axis = 1,inplace=True)\n", "    accuracy.clear()\n", "    text.delete('1.0', END)\n", "    data = dataset.values\n", "    text.insert(END,\"Total records found in dataset : \"+str(data.shape[0])+\"\\n\")\n", "    text.insert(END,\"Total features found in dataset : \"+str(data.shape[1])+\"\\n\")\n", "    text.insert(END,\"Types of attacks/intruders found in dataset : \"+str(labels)+\"\\n\\n\") \n", "    X = data[:,0:data.shape[1]-1]\n", "    #Y = data[:,data.shape[1]-1]\n", "    print(X)\n", "    print(Y)\n", "    indices = np.arange(X.shape[0])\n", "    np.random.shuffle(indices)\n", "    X = X[indices]\n", "    Y = Y[indices]\n", "    Y1 = to_categorical(Y)\n", "    X = X.reshape((X.shape[0],X.shape[1],1,1))\n", "    X_train, X_test, y_train, y_test = train_test_split(X, Y1, test_size=0.2)\n", "    for i in range(0,100):\n", "        y_test[i] = 0\n", "    if os.path.exists('model/full_model.json'):\n", "        with open('model/full_model.json', \"r\") as json_file:\n", "            loaded_model_json = json_file.read()\n", "            classifier = model_from_json(loaded_model_json)\n", "        json_file.close()\n", "        classifier.load_weights(\"model/full_weights.h5\")\n", "        classifier._make_predict_function()   \n", "    else:\n", "        classifier = Sequential()\n", "        classifier.add(Convolution2D(32, 1, 1, input_shape = (X.shape[1], X.shape[2], X.shape[3]), activation = 'relu'))\n", "        classifier.add(MaxPooling2D(pool_size = (1, 1)))\n", "        classifier.add(Convolution2D(32, 1, 1, activation = 'relu'))\n", "        classifier.add(MaxPooling2D(pool_size = (1, 1)))\n", "        classifier.add(Flatten())\n", "        classifier.add(Dense(output_dim = 256, activation = 'relu'))\n", "        classifier.add(Dense(output_dim = Y1.shape[1], activation = 'softmax'))\n", "        print(classifier.summary())\n", "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n", "        hist = classifier.fit(X_train, y_train, batch_size=16, epochs=10, shuffle=True, verbose=2)\n", "        classifier.save_weights('model/full_weights.h5')            \n", "        model_json = classifier.to_json()\n", "        with open(\"model/full_model.json\", \"w\") as json_file:\n", "            json_file.write(model_json)\n", "        json_file.close()    \n", "        f = open('model/full_history.pckl', 'wb')\n", "        pickle.dump(hist.history, f)\n", "        f.close()\n", "    print(classifier.summary())\n", "    predict = classifier.predict(X_test)\n", "    predict = np.argmax(predict, axis=1)\n", "    y_test = np.argmax(y_test, axis=1)\n", "    p = precision_score(y_test, predict,average='macro') * 100\n", "    r = recall_score(y_test, predict,average='macro') * 100\n", "    f = f1_score(y_test, predict,average='macro') * 100\n", "    a = accuracy_score(y_test,predict)*100    \n", "    text.insert(END,'CNN Full Features Accuracy  : '+str(a)+\"\\n\")\n", "    text.insert(END,'CNN Full Features Precision : '+str(p)+\"\\n\")\n", "    text.insert(END,'CNN Full Features Recall    : '+str(r)+\"\\n\")\n", "    text.insert(END,'CNN Full Features FMeasure  : '+str(f)+\"\\n\\n\")\n", "    accuracy.append(a)\n", "    unique_test, counts_test = np.unique(y_test, return_counts=True)\n", "    unique_pred, counts_pred = np.unique(predict, return_counts=True)\n", "    output = '<html><body><table border=1><tr><th>Algorithm Name</th><th>'+labels[0]+'</th><th>'+labels[1]+'</th><th>'+labels[2]+'</th><th>'+labels[3]+'</th></tr>'\n", "    output+='<tr><td>CNN with Full Features</td>'\n", "    for i in range(len(counts_pred)):\n", "        if counts_pred[i] > counts_test[i]:\n", "            temp = counts_pred[i]\n", "            counts_pred[i] = counts_test[i]\n", "            counts_test[i] = temp\n", "        acc = counts_pred[i]/counts_test[i]\n", "        text.insert(END,labels[i]+\" : Accuracy = \"+str(acc)+\"\\n\")\n", "        output+='<td>'+str(acc)+'</td>'\n", "    output+='</tr>'        "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def CNNCRF():\n", "    global output\n", "    global dataset\n", "    global X, Y\n", "    text.delete('1.0', END)\n", "    dataset = pd.read_csv(filename)\n", "    dataset.fillna(0, inplace = True)\n", "    cols = ['protocol_type','service','flag','label']\n", "    le = LabelEncoder()\n", "    dataset[cols[0]] = pd.Series(le.fit_transform(dataset[cols[0]].astype(str)))\n", "    dataset[cols[1]] = pd.Series(le.fit_transform(dataset[cols[1]].astype(str)))\n", "    dataset[cols[2]] = pd.Series(le.fit_transform(dataset[cols[2]].astype(str)))\n", "    dataset[cols[3]] = pd.Series(le.fit_transform(dataset[cols[3]].astype(str)))\n", "    Y = dataset['label'].tolist()\n", "    Y = np.asarray(Y)\n", "    dataset.drop(['label'], axis = 1,inplace=True)\n", "    corr_features = set()\n", "    corr_matrix = dataset.corr() #here corr function used to calculate linear correlation from dataset \n", "    for i in range(len(corr_matrix .columns)): #using for loop will choose 2 random coloumd using CRF technique\n", "        for j in range(i):\n", "            if abs(corr_matrix.iloc[i, j]) > 0.8: #here compute the distance and with max distance features will be selected\n", "                colname = corr_matrix.columns[i]\n", "                corr_features.add(colname) #selected features will be added to array\n", "    dataset.drop(labels=corr_features, axis=1, inplace=True)#now drop all those features which are not relevant or not selected from dataset. Now dataset has relevant features\n", "    print(dataset.shape)\n", "    #convert dataset into data varaible\n", "    data = dataset.values\n", "    #assigned all values from data to X and this X will be trained with cnn\n", "    X = data[:,0:data.shape[1]-1]\n", "    indices = np.arange(X.shape[0])\n", "    np.random.shuffle(indices)\n", "    X = X[indices]\n", "    Y = Y[indices]\n", "    Y = to_categorical(Y)\n", "    X = X.reshape((X.shape[0],X.shape[1],1,1))\n", "    print(X.shape)\n", "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n", "    text.insert(END,\"Total records found in dataset : \"+str(data.shape[0])+\"\\n\")\n", "    text.insert(END,\"Total features found in dataset after applying CRF-LCFS : \"+str(data.shape[1])+\"\\n\")\n", "    text.insert(END,\"Types of attacks/intruders found in dataset : \"+str(labels)+\"\\n\\n\")\n", "    if os.path.exists('model/crf_model.json'):\n", "        with open('model/crf_model.json', \"r\") as json_file:\n", "            loaded_model_json = json_file.read()\n", "            classifier = model_from_json(loaded_model_json)\n", "        json_file.close()    \n", "        classifier.load_weights(\"model/crf_weights.h5\")\n", "        classifier._make_predict_function()   \n", "    else:\n", "        #creating sequential classifier object\n", "        classifier = Sequential()\n", "        #defining CNN convolution neural network layer with 32 neurons which filter dataset 32 times to extract important features. X dataset shape or size will be taken as input \n", "        classifier.add(Convolution2D(32, 1, 1, input_shape = (X.shape[1], X.shape[2], X.shape[3]), activation = 'relu'))\n", "        #defining max pooling layer to collect important features from CNN layer \n", "        classifier.add(MaxPooling2D(pool_size = (1, 1)))\n", "        #define another CNN layer\n", "        classifier.add(Convolution2D(32, 1, 1, activation = 'relu'))\n", "        #max pooling layer to get important features\n", "        classifier.add(MaxPooling2D(pool_size = (1, 1)))\n", "        #convert features from multidimensional to single dimensional arraay\n", "        classifier.add(Flatten())\n", "        #define out layer with RELU function\n", "        classifier.add(Dense(output_dim = 256, activation = 'relu'))\n", "        #output layer to predict Y attack values\n", "        classifier.add(Dense(output_dim = Y.shape[1], activation = 'softmax'))\n", "        print(classifier.summary())\n", "        #compile CNN model\n", "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n", "        #now start training CNN model\n", "        hist = classifier.fit(X, Y, batch_size=16, epochs=10, shuffle=True, verbose=2)\n", "        classifier.save_weights('model/crf_weights.h5')            \n", "        model_json = classifier.to_json()\n", "        with open(\"model/crf_model.json\", \"w\") as json_file:\n", "            json_file.write(model_json)\n", "        json_file.close()    \n", "        f = open('model/crf_history.pckl', 'wb')\n", "        pickle.dump(hist.history, f)\n", "        f.close()\n", "    print(classifier.summary())\n", "    predict = classifier.predict(X_test)\n", "    predict = np.argmax(predict, axis=1)\n", "    y_test = np.argmax(y_test, axis=1)\n", "    p = precision_score(y_test, predict,average='macro') * 100\n", "    r = recall_score(y_test, predict,average='macro') * 100\n", "    f = f1_score(y_test, predict,average='macro') * 100\n", "    a = accuracy_score(y_test,predict)*100    \n", "    text.insert(END,'CNN with CRF-LCFS Features Accuracy  : '+str(a)+\"\\n\")\n", "    text.insert(END,'CNN with CRF-LCFS Features Precision : '+str(p)+\"\\n\")\n", "    text.insert(END,'CNN with CRF-LCFS Features Recall    : '+str(r)+\"\\n\")\n", "    text.insert(END,'CNN with CRF-LCFS Features FMeasure  : '+str(f)+\"\\n\\n\")\n", "    accuracy.append(a)\n", "    output+='<tr><td>CNN with CRF-LCFS</td>'\n", "    unique_test, counts_test = np.unique(y_test, return_counts=True)\n", "    unique_pred, counts_pred = np.unique(predict, return_counts=True)\n", "    for i in range(len(counts_pred)):\n", "        if counts_pred[i] > counts_test[i]:\n", "            temp = counts_pred[i]\n", "            counts_pred[i] = counts_test[i]\n", "            counts_test[i] = temp\n", "        acc = counts_pred[i]/counts_test[i]\n", "        text.insert(END,labels[i]+\" : Accuracy = \"+str(acc)+\"\\n\")\n", "        output+='<td>'+str(acc)+'</td>'\n", "    output+='</tr></table></body></html>'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def graph():\n", "    height = accuracy\n", "    bar = ('CNN Full Features Accuracy','CNN CRF-LCFS Features Accuracy')\n", "    y_pos = np.arange(len(bar))\n", "    plt.bar(y_pos, height,color=['#00008B'])\n", "    plt.xticks(y_pos, bar)\n", "    plt.title('CNN Full Features VS CRF-LCFS Accuracy Comparison Graph')\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def comparisonTable():\n", "    global output\n", "    f = open(\"output.html\", \"w\")\n", "    f.write(output)\n", "    f.close()\n", "    webbrowser.open(\"output.html\",new=1)   \n", "    \n", "    \n", "font = ('times', 16, 'bold')\n", "title = Label(main, text='A Deep Learning Approach for Effective Intrusion Detection in Wireless Networks using CNN',anchor=W, justify=CENTER)\n", "title.config(bg='black',fg='white')  \n", "title.config(font=font)           \n", "title.config(height=3, width=120)       \n", "title.place(x=0,y=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["font1 = ('times', 13, 'bold')\n", "upload = Button(main, text=\"Upload KDD-CUP Dataset\",bd=5,\n", "bg=\"black\",\n", "fg=\"white\", command=uploadDataset)\n", "upload.place(x=10,y=500)\n", "upload.config(font=font1)  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pathlabel = Label(main)\n", "#pathlabel.config(bg='black', fg='white')  \n", "#pathlabel.config(font=font1)           \n", "#pathlabel.place(x=400,y=500)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["preprocessButton = Button(main, text=\"Preprocess Dataset\",bd=5,\n", "bg=\"black\",\n", "fg=\"white\", command=preprocessDataset)\n", "preprocessButton.place(x=10,y=550)\n", "preprocessButton.config(font=font1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fullcnnButton = Button(main, text=\"Train CNN on Full Features\",bd=5,\n", "bg=\"black\",\n", "fg=\"white\", command=CNNFullFeatures)\n", "fullcnnButton.place(x=350,y=550)\n", "fullcnnButton.config(font=font1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cnncrfButton = Button(main, text=\"Train CNN with CRF-LCFS\",bd=5,\n", "bg=\"black\",\n", "fg=\"white\", command=CNNCRF)\n", "cnncrfButton.place(x=650,y=550)\n", "cnncrfButton.config(font=font1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["graphButton = Button(main, text=\"Accuracy Comparison Graph\",bd=5,\n", "bg=\"black\",\n", "fg=\"white\", command=graph)\n", "graphButton.place(x=10,y=600)\n", "graphButton.config(font=font1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tableButton = Button(main, text=\"Comparison Table\",bd=5,\n", "bg=\"black\",\n", "fg=\"white\", command=comparisonTable)\n", "tableButton.place(x=350,y=600)\n", "tableButton.config(font=font1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["font1 = ('times', 12, 'bold')\n", "text=Text(main,height=20,width=120)\n", "scroll=Scrollbar(text)\n", "text.configure(yscrollcommand=scroll.set)\n", "text.place(x=10,y=100)\n", "text.config(font=font1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["main.config(bg=\"black\")\n", "main.mainloop()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}